{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: unzip: command not found\n"
     ]
    }
   ],
   "source": [
    "# !unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('glove.6B.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the glove file\n",
    "def read_glove_file(glove_file):\n",
    "    counter = 0\n",
    "    with open(glove_file, 'r') as f:\n",
    "        word_to_vec = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            word = line[0]\n",
    "            vec = list(map(float, line[1:]))\n",
    "            if word.isalpha():\n",
    "                word_to_vec[word] = vec\n",
    "            counter += 1\n",
    "            if counter == 100:\n",
    "                break\n",
    "    return word_to_vec\n",
    "\n",
    "\n",
    "file = 'glove.6B.50d.txt'\n",
    "word_to_vec = read_glove_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['the', 'of', 'to', 'and', 'in', 'a', 'for', 'that', 'on', 'is', 'was', 'said', 'with', 'he', 'as', 'it', 'by', 'at', 'from', 'his', 'an', 'be', 'has', 'are', 'have', 'but', 'were', 'not', 'this', 'who', 'they', 'had', 'i', 'which', 'will', 'their', 'or', 'its', 'one', 'after', 'new', 'been', 'also', 'we', 'would', 'two', 'more', 'first', 'about', 'up', 'when', 'year', 'there', 'all', 'out', 'she', 'other', 'people', 'her', 'percent', 'than', 'over', 'into', 'last', 'some', 'government', 'time', 'you', 'years', 'if', 'no', 'world', 'can', 'three', 'do', 'president', 'only', 'state', 'million', 'could', 'us', 'most', 'against'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list = [word_to_vec[key] for key in word_to_vec.keys()]\n",
    "word_list = list(word_to_vec.keys())\n",
    "\n",
    "# Map word to a integer\n",
    "word_to_int = {word: i for i, word in enumerate(word_list)}\n",
    "int_to_word = {i: word for i, word in enumerate(word_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the embeddings list to tensor\n",
    "embeddings_tensor = torch.tensor(embeddings_list)\n",
    "# Convert the word list to tensor\n",
    "word_tensor = torch.tensor([word_to_int[word] for word in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming embeddings_list is a list of embeddings\n",
    "embeddings_np = np.array(embeddings_list)\n",
    "\n",
    "# Now you can convert its dtype to float32 if needed\n",
    "embeddings_np = embeddings_np.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = embeddings_tensor.numpy()\n",
    "\n",
    "# create a random matrix of 50x50 with float32\n",
    "embeddings = embeddings_np\n",
    "\n",
    "# check for float32\n",
    "assert embeddings.dtype == 'float32'\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "k = 5  # Number of nearest neighbors to retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding = embeddings[0]\n",
    "query_embedding = query_embedding.astype('float32')\n",
    "query_embedding = query_embedding.reshape(1, -1)\n",
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5  # Number of nearest neighbors to retrieve\n",
    "distances, indices = index.search(query_embedding, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.       , 3.7542362, 4.7945795, 4.809632 , 4.9880333]],\n",
       "       dtype=float32),\n",
       " array([[ 0, 33,  1,  4,  8]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'which', 'of', 'in', 'on']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_words = [int_to_word[idx] for idx in indices[0]]\n",
    "nearest_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the nearest words to the word 'the' in the glove embeddings. So when we finish the training, we need these words to also be the same as the words in the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Directly borrowed from https://github.com/RAIVNLab/MRL/blob/main/MRL.py\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "Loss function for Matryoshka Representation Learning \n",
    "'''\n",
    "\n",
    "class Matryoshka_CE_Loss(nn.Module):\n",
    "\tdef __init__(self, relative_importance: List[float]=None, **kwargs):\n",
    "\t\tsuper(Matryoshka_CE_Loss, self).__init__()\n",
    "\t\tself.criterion = nn.CrossEntropyLoss(**kwargs)\n",
    "\t\t# relative importance shape: [G]/\n",
    "\t\tself.relative_importance = relative_importance\n",
    "\n",
    "\tdef forward(self, output, target):\n",
    "\t\t# output shape: [G granularities, N batch size, C number of classes]\n",
    "\t\t# target shape: [N batch size]\n",
    "\n",
    "\t\t# Calculate losses for each output and stack them. This is still O(N)\n",
    "\t\tlosses = torch.stack([self.criterion(output_i, target) for output_i in output])\n",
    "\t\t\n",
    "\t\t# Set relative_importance to 1 if not specified\n",
    "\t\trel_importance = torch.ones_like(losses) if self.relative_importance is None else torch.tensor(self.relative_importance)\n",
    "\t\t\n",
    "\t\t# Apply relative importance weights\n",
    "\t\tweighted_losses = rel_importance * losses\n",
    "\t\treturn weighted_losses.sum()\n",
    "\n",
    "class MRL_Linear_Layer(nn.Module):\n",
    "\tdef __init__(self, nesting_list: List, num_classes=1000, efficient=False, **kwargs):\n",
    "\t\tsuper(MRL_Linear_Layer, self).__init__()\n",
    "\t\tself.nesting_list = nesting_list\n",
    "\t\tself.num_classes = num_classes # Number of classes for classification\n",
    "\t\tself.efficient = efficient\n",
    "\t\tif self.efficient:\n",
    "\t\t\tsetattr(self, f\"nesting_classifier_{0}\", nn.Linear(nesting_list[-1], self.num_classes, **kwargs))\t\t\n",
    "\t\telse:\t\n",
    "\t\t\tfor i, num_feat in enumerate(self.nesting_list):\n",
    "\t\t\t\tsetattr(self, f\"nesting_classifier_{i}\", nn.Linear(num_feat, self.num_classes, **kwargs))\t\n",
    "\n",
    "\tdef reset_parameters(self):\n",
    "\t\tif self.efficient:\n",
    "\t\t\tself.nesting_classifier_0.reset_parameters()\n",
    "\t\telse:\n",
    "\t\t\tfor i in range(len(self.nesting_list)):\n",
    "\t\t\t\tgetattr(self, f\"nesting_classifier_{i}\").reset_parameters()\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tnesting_logits = ()\n",
    "\t\tfor i, num_feat in enumerate(self.nesting_list):\n",
    "\t\t\tif self.efficient:\n",
    "\t\t\t\tif self.nesting_classifier_0.bias is None:\n",
    "\t\t\t\t\tnesting_logits += (torch.matmul(x[:, :num_feat], (self.nesting_classifier_0.weight[:, :num_feat]).t()), )\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnesting_logits += (torch.matmul(x[:, :num_feat], (self.nesting_classifier_0.weight[:, :num_feat]).t()) + self.nesting_classifier_0.bias, )\n",
    "\t\t\telse:\n",
    "\t\t\t\tnesting_logits +=  (getattr(self, f\"nesting_classifier_{i}\")(x[:, :num_feat]),)\n",
    "\n",
    "\t\treturn nesting_logits\n",
    "\n",
    "\n",
    "class FixedFeatureLayer(nn.Linear):\n",
    "    '''\n",
    "    For our fixed feature baseline, we just replace the classification layer with the following. \n",
    "    It effectively just look at the first \"in_features\" for the classification. \n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_features, out_features, **kwargs):\n",
    "        super(FixedFeatureLayer, self).__init__(in_features, out_features, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not (self.bias is None):\n",
    "            out = torch.matmul(x[:, :self.in_features], self.weight.t()) + self.bias\n",
    "        else:\n",
    "            out = torch.matmul(x[:, :self.in_features], self.weight.t())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Create a dataset and dataloader\n",
    "dataset = TensorDataset(embeddings_tensor, word_tensor)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 2.7660\n",
      "Epoch [200/1000], Loss: 0.8505\n",
      "Epoch [300/1000], Loss: 0.3562\n",
      "Epoch [400/1000], Loss: 0.1535\n",
      "Epoch [500/1000], Loss: 0.0628\n",
      "Epoch [600/1000], Loss: 0.0391\n",
      "Epoch [700/1000], Loss: 0.0299\n",
      "Epoch [800/1000], Loss: 0.0146\n",
      "Epoch [900/1000], Loss: 0.0152\n",
      "Epoch [1000/1000], Loss: 0.0102\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(50, 50),  # Reduce dimension from 50 to 25\n",
    "    MRL_Linear_Layer(nesting_list=[25], num_classes=1000, efficient=True),\n",
    ")\n",
    "\n",
    "# Define the loss function\n",
    "criterion = Matryoshka_CE_Loss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "n_epochs = 1000\n",
    "for epoch in range(n_epochs):\n",
    "    for embeddings, word in data_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, word)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'which', 'of', 'in', 'on']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the index, again\n",
    "embeddings = embeddings_tensor.numpy()\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Get the nearest neighbors\n",
    "query_embedding = embeddings[0]\n",
    "query_embedding = query_embedding.astype('float32')\n",
    "query_embedding = query_embedding.reshape(1, -1)\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Get the words for the indices\n",
    "nearest_words = [int_to_word[idx] for idx in indices[0]]\n",
    "nearest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the', 'also', 'on', 'one', 'as']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we will only use the first 25 dimensions of the embeddings\n",
    "embeddings = embeddings_tensor[:, :25].numpy()\n",
    "print(embeddings.shape)\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Get the nearest neighbors\n",
    "query_embedding = embeddings[0]\n",
    "query_embedding = query_embedding.astype('float32')\n",
    "query_embedding = query_embedding.reshape(1, -1)\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Get the words for the indices\n",
    "nearest_words = [int_to_word[idx] for idx in indices[0]]\n",
    "nearest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrl-HNuq7bEh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
